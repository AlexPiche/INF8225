{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction a PyTorch\n",
    "\n",
    "Based on https://github.com/mila-udem/welcome_tutorials/tree/master/pytorch By Sandeep Subramanian, https://github.com/jcjohnson/pytorch-examples by Justin Johnson and official documentation http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor\n",
    "\n",
    "Tensors are similar to numpy array, but they can also be used on GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       "[torch.LongTensor of size 4]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "# convert numpy array to tensor\n",
    "torch.from_numpy(np.array([1,2,3,4]))  # LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       "[torch.DoubleTensor of size 4]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.array([1.,2,3,4]))  # Double Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       "[torch.FloatTensor of size 4]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([1,2,3,4])\n",
    "torch.Tensor([1,2,3,4])  # float tensor by default, can change it with torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.Tensor([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.0000\n",
       " 1.4142\n",
       " 1.7321\n",
       " 2.0000\n",
       "[torch.FloatTensor of size 4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sqrt()  # similar functionality as numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "x = x.view(-1, 1)  # the torch reshape function\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  1\n",
       " 2  2\n",
       " 3  3\n",
       " 4  4\n",
       "[torch.FloatTensor of size 4x2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([x, x], 1)  # concatenate 2 vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "\n",
    "Autograd provides automatic differentiation on all operations perform on tensors. To be able to use Autograd, you must wrap your tensors in a Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.FloatTensor of size 4x1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(x, requires_grad=False)\n",
    "w = Variable(torch.ones(4, 1), requires_grad=True)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 10\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z = torch.dot(w, x)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optim and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([w], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      "[torch.FloatTensor of size 4x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "z.backward()\n",
    "print(w.grad)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.9900\n",
      " 0.9800\n",
      " 0.9700\n",
      " 0.9600\n",
      "[torch.FloatTensor of size 4x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.7960\n",
      " 0.5920\n",
      " 0.3880\n",
      " 0.1840\n",
      "[torch.FloatTensor of size 4x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "z = torch.dot(w, x)\n",
    "target = Variable(torch.zeros(1))\n",
    "optimizer.zero_grad()\n",
    "loss = loss_fn(z, target)\n",
    "loss.backward()  # retain_graph=True, if you need to call loss.backward() again without optimizer.step()\n",
    "optimizer.step()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST\n",
    "\n",
    "based on MNIST tutorial: https://github.com/pytorch/examples/blob/master/mnist/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from fashion import FashionMNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from secret_model import SecretModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = FashionMNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "valid_data = FashionMNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_idx = np.random.choice(train_data.train_data.shape[0], 54000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.train_data = train_data.train_data[train_idx, :]\n",
    "train_data.train_labels = train_data.train_labels[torch.from_numpy(train_idx).type(torch.LongTensor)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = np.ones(60000)\n",
    "mask[train_idx] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_data.train_data = valid_data.train_data[torch.from_numpy(np.argwhere(mask)), :].squeeze()\n",
    "valid_data.train_labels = valid_data.train_labels[torch.from_numpy(mask).type(torch.ByteTensor)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "test_batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data,\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    FashionMNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1159e0080>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDyRF+IGk/h/nhhA3UhBXeAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e62add8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_loader.dataset.train_data[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x115b8aa58>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQTazbKkeXP8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e62aef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_loader.dataset.train_data[10].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FcNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, image):\n",
    "        batch_size = image.size()[0]\n",
    "        x = image.view(batch_size, -1)\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)  # calls the forward function\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "def valid(model, valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in valid_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        valid_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    valid_loss /= len(valid_loader.dataset)\n",
    "    print('\\n' + \"valid\" + ' set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        valid_loss, correct, len(valid_loader.dataset),\n",
    "        100. * correct / len(valid_loader.dataset)))\n",
    "    return correct / len(valid_loader.dataset)\n",
    "\n",
    "    \n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data, volatile=True).cuda(), Variable(target).cuda()\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\n' + \"test\" + ' set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    \n",
    "def experiment(model, epochs=10, lr=0.001):\n",
    "    best_precision = 0\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model = train(model, train_loader, optimizer)\n",
    "        precision = valid(model, valid_loader)\n",
    "    \n",
    "        if precision > best_precision:\n",
    "            best_precision = precision\n",
    "            best_model = model\n",
    "    return best_model, best_precision\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid set: Average loss: 0.4312, Accuracy: 5090/6000 (85%)\n",
      "\n",
      "\n",
      "valid set: Average loss: 0.3640, Accuracy: 5224/6000 (87%)\n",
      "\n",
      "\n",
      "valid set: Average loss: 0.3484, Accuracy: 5285/6000 (88%)\n",
      "\n",
      "\n",
      "valid set: Average loss: 0.3287, Accuracy: 5289/6000 (88%)\n",
      "\n",
      "\n",
      "valid set: Average loss: 0.3343, Accuracy: 5273/6000 (88%)\n",
      "\n",
      "\n",
      "valid set: Average loss: 0.3293, Accuracy: 5276/6000 (88%)\n",
      "\n",
      "\n",
      "valid set: Average loss: 0.3104, Accuracy: 5323/6000 (89%)\n",
      "\n",
      "\n",
      "valid set: Average loss: 0.3229, Accuracy: 5323/6000 (89%)\n",
      "\n",
      "\n",
      "valid set: Average loss: 0.3085, Accuracy: 5332/6000 (89%)\n",
      "\n",
      "\n",
      "valid set: Average loss: 0.3052, Accuracy: 5357/6000 (89%)\n",
      "\n",
      "\n",
      "valid set: Average loss: 0.4538, Accuracy: 5001/6000 (83%)\n",
      "\n",
      "\n",
      "valid set: Average loss: 0.3728, Accuracy: 5207/6000 (87%)\n",
      "\n",
      "\n",
      "valid set: Average loss: 0.3649, Accuracy: 5220/6000 (87%)\n",
      "\n",
      "\n",
      "valid set: Average loss: 0.3309, Accuracy: 5281/6000 (88%)\n",
      "\n",
      "\n",
      "valid set: Average loss: 0.3304, Accuracy: 5279/6000 (88%)\n",
      "\n",
      "\n",
      "valid set: Average loss: 0.3215, Accuracy: 5278/6000 (88%)\n",
      "\n",
      "\n",
      "valid set: Average loss: 0.3031, Accuracy: 5347/6000 (89%)\n",
      "\n",
      "\n",
      "valid set: Average loss: 0.3035, Accuracy: 5333/6000 (89%)\n",
      "\n",
      "\n",
      "valid set: Average loss: 0.2888, Accuracy: 5372/6000 (90%)\n",
      "\n",
      "\n",
      "valid set: Average loss: 0.2887, Accuracy: 5364/6000 (89%)\n",
      "\n",
      "\n",
      "test set: Average loss: 0.2945, Accuracy: 8968/10000 (90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_precision = 0\n",
    "for model in [FcNetwork(), SecretModel()]:\n",
    "    model.cuda()\n",
    "    model, precision = experiment(model)\n",
    "    if precision > best_precision:\n",
    "        best_precision = precision\n",
    "        best_model = model\n",
    "\n",
    "test(best_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
